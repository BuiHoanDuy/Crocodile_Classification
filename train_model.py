"""
Script train model J-48 (Decision Tree) cho du doan Conservation Status cua ca sau
"""
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
import joblib
import json
import sys
import os

# Fix encoding for Windows console
if sys.platform == 'win32':
    try:
        # Try to set UTF-8 encoding
        os.system('chcp 65001 >nul 2>&1')
        # Also set environment variable
        os.environ['PYTHONIOENCODING'] = 'utf-8'
    except:
        pass

print("=" * 60)
print("TRAIN MODEL J-48 (DECISION TREE)")
print("=" * 60)

# 1. ƒê·ªåC D·ªÆ LI·ªÜU
print("\n[1] ƒêang ƒë·ªçc d·ªØ li·ªáu...")
df = pd.read_csv('crocodile_processed_complete.csv')
print(f"   ‚úì ƒê√£ ƒë·ªçc {len(df)} d√≤ng d·ªØ li·ªáu")
print(f"   ‚úì C√°c c·ªôt: {list(df.columns)}")

# 2. CHU·∫®N B·ªä D·ªÆ LI·ªÜU
print("\n[2] ƒêang chu·∫©n b·ªã d·ªØ li·ªáu...")

# X·ª≠ l√Ω gi√° tr·ªã thi·∫øu
df = df.dropna()

# X√°c ƒë·ªãnh features v√† target
feature_cols = [
    'Observed Length (m)',
    'Observed Weight (kg)',
    'Age Class',
    'Sex',
    'Country/Region',
    'Habitat Type',
    'Continent'
]

target_col = 'Conservation Status'

# Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i
missing_cols = [col for col in feature_cols if col not in df.columns]
if missing_cols:
    print(f"   ‚ö† C·∫£nh b√°o: Thi·∫øu c√°c c·ªôt {missing_cols}")
    feature_cols = [col for col in feature_cols if col in df.columns]

X = df[feature_cols].copy()
y = df[target_col].copy()

print(f"   ‚úì Features: {len(feature_cols)} c·ªôt")
print(f"   ‚úì Target: {target_col}")
print(f"   ‚úì S·ªë l∆∞·ª£ng m·∫´u: {len(X)}")

# 3. M√É H√ìA D·ªÆ LI·ªÜU
print("\n[3] ƒêang m√£ h√≥a d·ªØ li·ªáu...")

# M√£ h√≥a Age Class
age_mapping = {'Hatchling': 0, 'Juvenile': 1, 'Subadult': 2, 'Adult': 3}
if 'Age Class' in X.columns:
    X['Age Class'] = X['Age Class'].map(age_mapping).fillna(2)

# M√£ h√≥a Sex
sex_le = LabelEncoder()
if 'Sex' in X.columns:
    X['Sex'] = sex_le.fit_transform(X['Sex'].astype(str))

# M√£ h√≥a Country/Region
country_le = LabelEncoder()
if 'Country/Region' in X.columns:
    X['Country/Region'] = country_le.fit_transform(X['Country/Region'].astype(str))

# M√£ h√≥a Habitat Type
habitat_le = LabelEncoder()
if 'Habitat Type' in X.columns:
    X['Habitat Type'] = habitat_le.fit_transform(X['Habitat Type'].astype(str))

# M√£ h√≥a Continent
continent_le = LabelEncoder()
if 'Continent' in X.columns:
    X['Continent'] = continent_le.fit_transform(X['Continent'].astype(str))

# M√£ h√≥a Target (Conservation Status)
target_le = LabelEncoder()
y_encoded = target_le.fit_transform(y)

print(f"   ‚úì ƒê√£ m√£ h√≥a c√°c bi·∫øn ph√¢n lo·∫°i")
print(f"   ‚úì S·ªë l·ªõp target: {len(target_le.classes_)}")
print(f"   ‚úì C√°c l·ªõp: {list(target_le.classes_)}")

# 4. CHU·∫®N H√ìA D·ªÆ LI·ªÜU S·ªê
print("\n[4] ƒêang chu·∫©n h√≥a d·ªØ li·ªáu s·ªë...")
numeric_cols = ['Observed Length (m)', 'Observed Weight (kg)']
scaler = StandardScaler()
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])
print(f"   ‚úì ƒê√£ chu·∫©n h√≥a c√°c c·ªôt s·ªë: {numeric_cols}")

# 5. CHIA D·ªÆ LI·ªÜU TRAIN/TEST
print("\n[5] ƒêang chia d·ªØ li·ªáu train/test...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)
print(f"   ‚úì Train: {len(X_train)} m·∫´u")
print(f"   ‚úì Test: {len(X_test)} m·∫´u")

# 6. TRAIN MODEL J-48 (DECISION TREE)
print("\n[6] ƒêang train model J-48...")
# J-48 t∆∞∆°ng ƒë∆∞∆°ng v·ªõi Decision Tree v·ªõi c√°c tham s·ªë:
# - criterion='entropy' (gi·ªëng J-48)
# - min_samples_split=2 (m·∫∑c ƒë·ªãnh)
# - min_samples_leaf=1 (m·∫∑c ƒë·ªãnh)
model = DecisionTreeClassifier(
    criterion='entropy',  # J-48 s·ª≠ d·ª•ng entropy
    max_depth=None,       # Kh√¥ng gi·ªõi h·∫°n ƒë·ªô s√¢u (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh)
    min_samples_split=2,
    min_samples_leaf=1,
    random_state=42
)

model.fit(X_train, y_train)
print("   ‚úì Model ƒë√£ ƒë∆∞·ª£c train th√†nh c√¥ng")

# 7. ƒê√ÅNH GI√Å MODEL
print("\n[7] ƒêang ƒë√°nh gi√° model...")
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)
accuracy = accuracy_score(y_test, y_pred)

# T√≠nh to√°n confusion matrix
cm = confusion_matrix(y_test, y_pred)

# T√≠nh to√°n c√°c metrics chi ti·∫øt
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"\n   üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å:")
print(f"   ‚úì ƒê·ªô ch√≠nh x√°c (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"   ‚úì Precision (weighted): {precision:.4f}")
print(f"   ‚úì Recall (weighted): {recall:.4f}")
print(f"   ‚úì F1-Score (weighted): {f1:.4f}")
print(f"\n   üìã Classification Report:")
report_str = classification_report(y_test, y_pred, target_names=target_le.classes_)
print(report_str)

# 7.1. L∆ØU K·∫æT QU·∫¢ V√ÄO FOLDER RESULT
print("\n[7.1] ƒêang l∆∞u k·∫øt qu·∫£ ƒë√°nh gi√° v√†o folder result...")
os.makedirs('result', exist_ok=True)

# L∆∞u classification report
with open('result/classification_report.txt', 'w', encoding='utf-8') as f:
    f.write("=" * 60 + "\n")
    f.write("CLASSIFICATION REPORT\n")
    f.write("=" * 60 + "\n\n")
    f.write(f"Model: J-48 (Decision Tree)\n")
    f.write(f"Criterion: entropy\n")
    f.write(f"Train samples: {len(X_train)}\n")
    f.write(f"Test samples: {len(X_test)}\n\n")
    f.write("=" * 60 + "\n")
    f.write("METRICS SUMMARY\n")
    f.write("=" * 60 + "\n")
    f.write(f"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\n")
    f.write(f"Precision (weighted): {precision:.4f}\n")
    f.write(f"Recall (weighted): {recall:.4f}\n")
    f.write(f"F1-Score (weighted): {f1:.4f}\n\n")
    f.write("=" * 60 + "\n")
    f.write("DETAILED CLASSIFICATION REPORT\n")
    f.write("=" * 60 + "\n\n")
    f.write(report_str)
    f.write("\n" + "=" * 60 + "\n")
    f.write("CONFUSION MATRIX\n")
    f.write("=" * 60 + "\n\n")
    f.write("Classes: " + ", ".join(target_le.classes_) + "\n\n")
    f.write(str(cm))
    f.write("\n")

# L∆∞u confusion matrix d·∫°ng JSON
cm_dict = {
    'confusion_matrix': cm.tolist(),
    'classes': target_le.classes_.tolist(),
    'accuracy': float(accuracy),
    'precision_weighted': float(precision),
    'recall_weighted': float(recall),
    'f1_weighted': float(f1)
}

with open('result/confusion_matrix.json', 'w', encoding='utf-8') as f:
    json.dump(cm_dict, f, indent=2, ensure_ascii=False)

# L∆∞u metrics t·ªïng h·ª£p
metrics_summary = {
    'model_type': 'J-48 (Decision Tree)',
    'criterion': 'entropy',
    'train_samples': len(X_train),
    'test_samples': len(X_test),
    'accuracy': float(accuracy),
    'accuracy_percent': float(accuracy * 100),
    'precision_weighted': float(precision),
    'recall_weighted': float(recall),
    'f1_weighted': float(f1),
    'target_classes': target_le.classes_.tolist(),
    'feature_columns': feature_cols
}

with open('result/metrics_summary.json', 'w', encoding='utf-8') as f:
    json.dump(metrics_summary, f, indent=2, ensure_ascii=False)

print("   ‚úì ƒê√£ l∆∞u classification_report.txt")
print("   ‚úì ƒê√£ l∆∞u confusion_matrix.json")
print("   ‚úì ƒê√£ l∆∞u metrics_summary.json")

# 8. L∆ØU MODEL V√Ä C√ÅC ENCODER
print("\n[8] ƒêang l∆∞u model v√† c√°c encoder...")

# L∆∞u model
joblib.dump(model, 'model_j48.pkl')
print("   ‚úì ƒê√£ l∆∞u model: model_j48.pkl")

# L∆∞u c√°c encoder v√† scaler
joblib.dump(sex_le, 'encoders/sex_encoder.pkl')
joblib.dump(country_le, 'encoders/country_encoder.pkl')
joblib.dump(habitat_le, 'encoders/habitat_encoder.pkl')
joblib.dump(continent_le, 'encoders/continent_encoder.pkl')
joblib.dump(target_le, 'encoders/target_encoder.pkl')
joblib.dump(scaler, 'encoders/scaler.pkl')
print("   ‚úì ƒê√£ l∆∞u c√°c encoder v√† scaler")

# L∆∞u metadata
metadata = {
    'feature_columns': feature_cols,
    'target_classes': target_le.classes_.tolist(),
    'age_mapping': age_mapping,
    'accuracy': float(accuracy),
    'n_samples_train': len(X_train),
    'n_samples_test': len(X_test),
    'model_type': 'J-48 (Decision Tree)',
    'criterion': 'entropy'
}

with open('model_metadata.json', 'w', encoding='utf-8') as f:
    json.dump(metadata, f, indent=2, ensure_ascii=False)
print("   ‚úì ƒê√£ l∆∞u metadata: model_metadata.json")

# L∆∞u mapping cho API
mapping_data = {
    'sex_classes': sex_le.classes_.tolist() if hasattr(sex_le, 'classes_') else [],
    'country_classes': country_le.classes_.tolist() if hasattr(country_le, 'classes_') else [],
    'habitat_classes': habitat_le.classes_.tolist() if hasattr(habitat_le, 'classes_') else [],
    'continent_classes': continent_le.classes_.tolist() if hasattr(continent_le, 'classes_') else [],
    'target_classes': target_le.classes_.tolist() if hasattr(target_le, 'classes_') else [],
    'age_mapping': age_mapping
}

with open('mappings.json', 'w', encoding='utf-8') as f:
    json.dump(mapping_data, f, indent=2, ensure_ascii=False)
print("   ‚úì ƒê√£ l∆∞u mappings: mappings.json")

print("\n" + "=" * 60)
print("‚úÖ HO√ÄN TH√ÄNH TRAIN MODEL!")
print("=" * 60)
print("\nC√°c file ƒë√£ t·∫°o:")
print("  - model_j48.pkl (model ƒë√£ train)")
print("  - encoders/ (th∆∞ m·ª•c ch·ª©a c√°c encoder)")
print("  - model_metadata.json (th√¥ng tin model)")
print("  - mappings.json (mapping c√°c gi√° tr·ªã)")
print("  - result/classification_report.txt (b√°o c√°o chi ti·∫øt)")
print("  - result/confusion_matrix.json (ma tr·∫≠n nh·∫ßm l·∫´n)")
print("  - result/metrics_summary.json (t·ªïng h·ª£p metrics)")
print("\nTi·∫øp theo: Ch·∫°y API v·ªõi l·ªánh: uvicorn main:app --reload")

